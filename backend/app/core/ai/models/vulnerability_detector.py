import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import LabelEncoder
import numpy as np

class VulnerabilityDetector:
    def __init__(self):
        self.model = self._build_model()
        self.label_encoder = LabelEncoder()

    def _build_model(self):
        model = models.Sequential([
            layers.Input(shape=(1000,)),  # Input layer for text features
            layers.Dense(512, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(128, activation='relu'),
            layers.Dense(5, activation='softmax')  # Output layer for vulnerability categories
        ])

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        return model

    def preprocess_text(self, text):
        # Convert text to numerical features (simplified for demo)
        # In production, use proper text vectorization
        return tf.keras.preprocessing.sequence.pad_sequences(
            [list(text.encode())], maxlen=1000, padding='post'
        )[0]

    def predict_vulnerability(self, input_data):
        # Preprocess input data
        features = self.preprocess_text(input_data)
        features = features.reshape(1, -1)

        # Make prediction
        prediction = self.model.predict(features)
        vulnerability_type = np.argmax(prediction)
        confidence = np.max(prediction)

        return {
            'vulnerability_type': vulnerability_type,
            'confidence': float(confidence),
            'severity': self._calculate_severity(confidence)
        }

    def _calculate_severity(self, confidence):
        if confidence > 0.9:
            return 'CRITICAL'
        elif confidence > 0.7:
            return 'HIGH'
        elif confidence > 0.5:
            return 'MEDIUM'
        elif confidence > 0.3:
            return 'LOW'
        return 'INFO'

    def train(self, X_train, y_train, epochs=10, batch_size=32):
        # Encode labels
        y_encoded = self.label_encoder.fit_transform(y_train)

        # Train model
        self.model.fit(
            X_train,
            y_encoded,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2
        )
